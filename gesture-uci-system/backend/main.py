"""
Script principal para ejecutar DOCommunication Backend

Opciones:
1. python main.py api - Iniciar API REST
2. python main.py demo - Ejecutar demo de an√°lisis de grafos
3. python main.py camera - Ejecutar detecci√≥n de gestos con c√°mara
"""

import sys
import argparse
from pathlib import Path

# Agregar src al path
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))


def run_api():
    """Inicia el servidor API REST"""
    import uvicorn
    from src.api.main import app

    print("üöÄ Iniciando DOCommunication API...")
    print("üìñ Documentaci√≥n: http://localhost:8000/docs")
    print("üîç Health check: http://localhost:8000/health")

    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        reload=True
    )


def run_demo():
    """Ejecuta demo de an√°lisis de grafos"""
    from src.graph.analyzer import InteractionGraphAnalyzer
    from src.utils.data_generator import DataGenerator

    print("üéÆ Demo: An√°lisis de Grafos de Interacciones\n")

    # Generar datos simulados
    print("üìä Generando datos simulados...")
    interactions = DataGenerator.generate_community_based()
    print(f"‚úÖ Generadas {len(interactions)} interacciones\n")

    # Crear analizador
    print("üîß Construyendo grafo de interacciones...")
    analyzer = InteractionGraphAnalyzer()
    analyzer.build_from_interactions(interactions)
    print(f"‚úÖ Grafo construido: {analyzer.graph.number_of_nodes()} nodos, "
          f"{analyzer.graph.number_of_edges()} aristas\n")

    # Calcular m√©tricas
    print("üìà Calculando m√©tricas del grafo...")
    metrics = analyzer.compute_all_metrics()

    print("\n" + "="*60)
    print("M√âTRICAS DEL GRAFO")
    print("="*60)

    print(f"\nüìä Topolog√≠a:")
    print(f"  ‚Ä¢ Nodos: {metrics.num_nodes}")
    print(f"  ‚Ä¢ Aristas: {metrics.num_edges}")
    print(f"  ‚Ä¢ Densidad: {metrics.density:.3f}")
    print(f"  ‚Ä¢ Di√°metro: {metrics.diameter}")
    print(f"  ‚Ä¢ Camino promedio: {metrics.avg_path_length:.3f}" if metrics.avg_path_length else "  ‚Ä¢ Camino promedio: N/A")
    print(f"  ‚Ä¢ Clustering promedio: {metrics.avg_clustering_coefficient:.3f}")

    print(f"\nüåê Comunidades:")
    print(f"  ‚Ä¢ N√∫mero de comunidades: {metrics.num_communities}")
    print(f"  ‚Ä¢ Modularidad: {metrics.modularity_score:.3f}")

    print(f"\nüéØ Top 3 Nodos por PageRank:")
    top_pagerank = sorted(
        metrics.node_metrics,
        key=lambda x: x.pagerank,
        reverse=True
    )[:3]
    for i, node in enumerate(top_pagerank, 1):
        print(f"  {i}. {node.node_id}: {node.pagerank:.3f}")

    print(f"\nüéØ Top 3 Nodos por Betweenness:")
    top_betweenness = sorted(
        metrics.node_metrics,
        key=lambda x: x.betweenness_centrality,
        reverse=True
    )[:3]
    for i, node in enumerate(top_betweenness, 1):
        print(f"  {i}. {node.node_id}: {node.betweenness_centrality:.3f}")

    print(f"\nüõ°Ô∏è Robustez:")
    print(f"  ‚Ä¢ Nodos cr√≠ticos: {', '.join(metrics.robustness.critical_nodes)}")
    print(f"  ‚Ä¢ Vulnerability score: {metrics.robustness.vulnerability_score:.3f}")
    print(f"  ‚Ä¢ P√©rdida de conectividad: {metrics.robustness.connectivity_loss:.1%}")

    print(f"\nüîÑ Transiciones:")
    print(f"  ‚Ä¢ Entrop√≠a: {metrics.transitions.entropy:.3f}")
    print(f"  ‚Ä¢ Burstiness: {metrics.transitions.burstiness:.3f}")
    print(f"  ‚Ä¢ Caminos comunes:")
    for i, path in enumerate(metrics.transitions.most_common_paths[:3], 1):
        print(f"    {i}. {' ‚Üí '.join(path)}")

    print(f"\nüí´ Difusi√≥n:")
    print(f"  ‚Ä¢ Threshold: {metrics.diffusion.activation_threshold:.2f}")
    print(f"  ‚Ä¢ Influence maximizers: {', '.join(metrics.diffusion.influence_maximizers)}")

    # Visualizar grafo
    print(f"\nüé® Generando visualizaci√≥n del grafo...")
    output_path = Path(__file__).parent / "visualizations" / "demo_graph.png"
    output_path.parent.mkdir(exist_ok=True)
    analyzer.visualize_graph(str(output_path))

    print("\n‚úÖ Demo completado!")


def run_camera():
    """Ejecuta detecci√≥n de gestos en tiempo real con c√°mara"""
    import cv2
    from src.vision.detector import GestureDetector

    print("üìπ Iniciando detecci√≥n de gestos con c√°mara...\n")
    print("Controles:")
    print("  ‚Ä¢ ESC - Salir")
    print("  ‚Ä¢ ESPACIO - Capturar frame")
    print()

    # Inicializar c√°mara
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("‚ùå Error: No se pudo abrir la c√°mara")
        return

    # Inicializar detector
    detector = GestureDetector()

    print("‚úÖ C√°mara iniciada. Presiona ESC para salir.\n")

    try:
        while True:
            ret, frame = cap.read()

            if not ret:
                print("‚ùå Error al leer frame")
                break

            # Procesar frame
            annotated_frame, landmark_data, gesture_state = detector.process_frame(frame)

            # Mostrar estado de gestos
            status_text = []

            if gesture_state.left_arm_l:
                status_text.append("‚úÖ Brazo IZQ en L")
            if gesture_state.right_arm_l:
                status_text.append("‚úÖ Brazo DER en L")
            if gesture_state.thumbs_up:
                status_text.append("üëç Thumbs Up")

            # Dibujar texto en frame
            y_offset = 30
            for text in status_text:
                cv2.putText(
                    annotated_frame,
                    text,
                    (10, y_offset),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    (0, 255, 0),
                    2
                )
                y_offset += 35

            # Mostrar √°ngulos
            if gesture_state.left_angle:
                cv2.putText(
                    annotated_frame,
                    f"L Angle: {gesture_state.left_angle:.1f}¬∞",
                    (10, annotated_frame.shape[0] - 60),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (255, 255, 255),
                    2
                )

            if gesture_state.right_angle:
                cv2.putText(
                    annotated_frame,
                    f"R Angle: {gesture_state.right_angle:.1f}¬∞",
                    (10, annotated_frame.shape[0] - 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (255, 255, 255),
                    2
                )

            # Mostrar frame
            cv2.imshow('DOCommunication - Gesture Detection', annotated_frame)

            # Manejar teclas
            key = cv2.waitKey(1) & 0xFF

            if key == 27:  # ESC
                break
            elif key == 32:  # ESPACIO
                # Guardar captura
                capture_path = Path(__file__).parent / "visualizations" / "capture.png"
                capture_path.parent.mkdir(exist_ok=True)
                cv2.imwrite(str(capture_path), annotated_frame)
                print(f"üì∏ Captura guardada: {capture_path}")

    finally:
        cap.release()
        cv2.destroyAllWindows()
        detector.close()
        print("\n‚úÖ C√°mara cerrada")


def main():
    """Funci√≥n principal"""
    parser = argparse.ArgumentParser(
        description="DOCommunication Backend - Sistema de Comunicaci√≥n Gestual UCI"
    )

    parser.add_argument(
        "mode",
        choices=["api", "demo", "camera"],
        help="Modo de ejecuci√≥n: api (servidor REST), demo (an√°lisis de grafos), camera (detecci√≥n en tiempo real)"
    )

    args = parser.parse_args()

    print("="*60)
    print("DOCommunication Backend v1.0")
    print("Sistema de Comunicaci√≥n Gestual para UCI")
    print("="*60)
    print()

    if args.mode == "api":
        run_api()
    elif args.mode == "demo":
        run_demo()
    elif args.mode == "camera":
        run_camera()


if __name__ == "__main__":
    main()
